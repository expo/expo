{"version":3,"file":"concurrency.js","sourceRoot":"","sources":["../src/concurrency.ts"],"names":[],"mappings":";;;AAYO,MAAM,aAAa,GAAG,CAAC,KAAa,EAAW,EAAE;IACtD,IAAI,OAAO,GAAG,CAAC,CAAC;IAChB,IAAI,IAAI,GAAqB,IAAI,CAAC;IAClC,IAAI,IAAI,GAAqB,IAAI,CAAC;IAElC,MAAM,OAAO,GAAG,GAAG,EAAE,CACnB,IAAI,OAAO,CAAO,CAAC,OAAO,EAAE,EAAE;QAC5B,MAAM,IAAI,GAAc,EAAE,OAAO,EAAE,IAAI,EAAE,IAAI,EAAE,CAAC;QAChD,IAAI,IAAI,EAAE,CAAC;YACT,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC;YACjB,IAAI,GAAG,IAAI,CAAC;QACd,CAAC;aAAM,CAAC;YACN,IAAI,GAAG,IAAI,CAAC;YACZ,IAAI,GAAG,IAAI,CAAC;QACd,CAAC;IACH,CAAC,CAAC,CAAC;IAEL,MAAM,OAAO,GAAG,GAAG,EAAE;QACnB,IAAI,OAAO,GAAG,KAAK,IAAI,IAAI,KAAK,IAAI,EAAE,CAAC;YACrC,MAAM,EAAE,OAAO,EAAE,IAAI,EAAE,GAAG,IAAI,CAAC;YAC/B,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC;YACjB,IAAI,GAAG,IAAI,CAAC;YACZ,IAAI,IAAI,KAAK,IAAI,EAAE,CAAC;gBAClB,IAAI,GAAG,IAAI,CAAC;YACd,CAAC;YACD,OAAO,EAAE,CAAC;YACV,OAAO,EAAE,CAAC;QACZ,CAAC;IACH,CAAC,CAAC;IAEF,OAAO,KAAK,EAAE,EAAE,EAAE,GAAG,IAAI,EAAE,EAAE;QAC3B,IAAI,OAAO,GAAG,KAAK,EAAE,CAAC;YACpB,OAAO,EAAE,CAAC;QACZ,CAAC;aAAM,CAAC;YACN,MAAM,OAAO,EAAE,CAAC;QAClB,CAAC;QACD,IAAI,CAAC;YACH,OAAO,MAAM,EAAE,CAAC,GAAG,IAAI,CAAC,CAAC;QAC3B,CAAC;gBAAS,CAAC;YACT,OAAO,EAAE,CAAC;YACV,OAAO,EAAE,CAAC;QACZ,CAAC;IACH,CAAC,CAAC;AACJ,CAAC,CAAC;AA3CW,QAAA,aAAa,iBA2CxB;AAEK,MAAM,OAAO,GAAG,CAAO,MAAW,EAAE,GAA6B,EAAgB,EAAE;IACxF,iFAAiF;IACjF,iFAAiF;IACjF,iFAAiF;IACjF,kFAAkF;IAClF,iFAAiF;IACjF,uEAAuE;IACvE,MAAM,OAAO,GAAG,IAAA,qBAAa,EAAC,CAAC,CAAC,CAAC;IACjC,OAAO,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,KAAK,EAAE,EAAE,CAAC,OAAO,CAAC,GAAG,EAAE,KAAK,CAAC,CAAC,CAAC,CAAC;AACjE,CAAC,CAAC;AATW,QAAA,OAAO,WASlB","sourcesContent":["export interface Limiter {\n  <Arguments extends unknown[], ReturnType>(\n    fn: (...args: Arguments) => PromiseLike<ReturnType> | ReturnType,\n    ...args: Arguments\n  ): Promise<ReturnType>;\n}\n\ninterface QueueItem {\n  resolve(): void;\n  next: QueueItem | null;\n}\n\nexport const createLimiter = (limit: number): Limiter => {\n  let running = 0;\n  let head: QueueItem | null = null;\n  let tail: QueueItem | null = null;\n\n  const enqueue = () =>\n    new Promise<void>((resolve) => {\n      const item: QueueItem = { resolve, next: null };\n      if (tail) {\n        tail.next = item;\n        tail = item;\n      } else {\n        head = item;\n        tail = item;\n      }\n    });\n\n  const dequeue = () => {\n    if (running < limit && head !== null) {\n      const { resolve, next } = head;\n      head.next = null;\n      head = next;\n      if (head === null) {\n        tail = null;\n      }\n      running++;\n      resolve();\n    }\n  };\n\n  return async (fn, ...args) => {\n    if (running < limit) {\n      running++;\n    } else {\n      await enqueue();\n    }\n    try {\n      return await fn(...args);\n    } finally {\n      running--;\n      dequeue();\n    }\n  };\n};\n\nexport const taskAll = <T, R>(inputs: T[], map: (input: T) => Promise<R>): Promise<R[]> => {\n  // NOTE: This doesn't depend on CPU cores, but instead is hard-coded depending on\n  // number of concurrent IO-bound tasks. `taskAll` can be called concurrently, and\n  // we don't keep track of concurrent `taskAll` calls in expo-modules-autolinking.\n  // There's a fixed number of concurrent pending IO operations that Node.js handles\n  // nicely. It seems that expo-modules-autolinking behaves nicely when this number\n  // is around ~8, but this may be higher if disk + core speed is higher.\n  const limiter = createLimiter(8);\n  return Promise.all(inputs.map((input) => limiter(map, input)));\n};\n"]}